{"cells":[{"cell_type":"code","source":["import requests\n","import pandas as pd\n","from pyspark.sql import SparkSession\n","\n","# Initialize Spark session\n","spark = SparkSession.builder.appName(\"GitHubCSVFetcher\").getOrCreate()\n","\n","# GitHub repository details\n","GITHUB_OWNER = \"Rulzyushan\"\n","REPO_NAME = \"Data-Engineering-Batch-Processing-Project-01\"\n","FOLDER_PATH = \"DE-BP-Project-01-Data\"  # e.g., \"data\"\n","GITHUB_API_URL = f\"https://api.github.com/repos/{GITHUB_OWNER}/{REPO_NAME}/contents/{FOLDER_PATH}\"\n","\n","def get_csv_urls_from_github(api_url):\n","    response = requests.get(api_url)\n","    if response.status_code == 200:\n","        files = response.json()\n","        csv_urls = [{\"file_name\": file[\"name\"], \"csv_url\": file[\"download_url\"]} \n","                    for file in files if file[\"name\"].endswith(\".csv\")]\n","        return csv_urls\n","    else:\n","        print(f\"Failed to fetch data: {response.status_code}\")\n","        return []\n","\n","# Get all CSV file URLs\n","csv_urls = get_csv_urls_from_github(GITHUB_API_URL)\n","\n","# Print the CSV URLs\n","#for csv in csv_urls:\n","#    print(f\"File Name: {csv['file_name']}, CSV URL: {csv['csv_url']}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"13956826-d9b6-4d6d-a0e0-6af303be61a8","normalized_state":"finished","queued_time":"2025-03-23T08:31:59.6113556Z","session_start_time":null,"execution_start_time":"2025-03-23T08:31:59.6132795Z","execution_finish_time":"2025-03-23T08:32:00.6099607Z","parent_msg_id":"6dfeab24-534d-4da4-8460-06713ef053cb"}},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"129020f6-fbd5-4a8b-aa37-d1c0939d0b06"},{"cell_type":"code","source":["display(csv_urls)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"13956826-d9b6-4d6d-a0e0-6af303be61a8","normalized_state":"finished","queued_time":"2025-03-23T08:32:09.6802631Z","session_start_time":null,"execution_start_time":"2025-03-23T08:32:09.6821894Z","execution_finish_time":"2025-03-23T08:32:11.1454364Z","parent_msg_id":"cf008799-cc2d-428e-98ba-2948bcf5ea62"}},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.synapse-jupyter.display-view+json":{"table":{"rows":[{"0":"SalesLT.Address.csv","1":"https://raw.githubusercontent.com/Rulzyushan/Data-Engineering-Batch-Processing-Project-01-AZURE/main/DE-BP-Project-01-Data/SalesLT.Address.csv"},{"0":"SalesLT.Customer.csv","1":"https://raw.githubusercontent.com/Rulzyushan/Data-Engineering-Batch-Processing-Project-01-AZURE/main/DE-BP-Project-01-Data/SalesLT.Customer.csv"},{"0":"SalesLT.CustomerAddress.csv","1":"https://raw.githubusercontent.com/Rulzyushan/Data-Engineering-Batch-Processing-Project-01-AZURE/main/DE-BP-Project-01-Data/SalesLT.CustomerAddress.csv"},{"0":"SalesLT.Product.csv","1":"https://raw.githubusercontent.com/Rulzyushan/Data-Engineering-Batch-Processing-Project-01-AZURE/main/DE-BP-Project-01-Data/SalesLT.Product.csv"},{"0":"SalesLT.ProductCategory.csv","1":"https://raw.githubusercontent.com/Rulzyushan/Data-Engineering-Batch-Processing-Project-01-AZURE/main/DE-BP-Project-01-Data/SalesLT.ProductCategory.csv"},{"0":"SalesLT.ProductDescription.csv","1":"https://raw.githubusercontent.com/Rulzyushan/Data-Engineering-Batch-Processing-Project-01-AZURE/main/DE-BP-Project-01-Data/SalesLT.ProductDescription.csv"},{"0":"SalesLT.ProductModel.csv","1":"https://raw.githubusercontent.com/Rulzyushan/Data-Engineering-Batch-Processing-Project-01-AZURE/main/DE-BP-Project-01-Data/SalesLT.ProductModel.csv"},{"0":"SalesLT.ProductModelProductDescription.csv","1":"https://raw.githubusercontent.com/Rulzyushan/Data-Engineering-Batch-Processing-Project-01-AZURE/main/DE-BP-Project-01-Data/SalesLT.ProductModelProductDescription.csv"},{"0":"SalesLT.SalesOrderDetail.csv","1":"https://raw.githubusercontent.com/Rulzyushan/Data-Engineering-Batch-Processing-Project-01-AZURE/main/DE-BP-Project-01-Data/SalesLT.SalesOrderDetail.csv"},{"0":"SalesLT.SalesOrderHeader.csv","1":"https://raw.githubusercontent.com/Rulzyushan/Data-Engineering-Batch-Processing-Project-01-AZURE/main/DE-BP-Project-01-Data/SalesLT.SalesOrderHeader.csv"}],"schema":[{"key":"0","name":"file_name","type":"string"},{"key":"1","name":"csv_url","type":"string"}],"truncated":false},"isSummary":false,"language":"python"}},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"9939159c-49b2-483f-865d-c55180cfeced"},{"cell_type":"code","source":["import pandas as pd\n","\n","def read_dataframe(url):\n","    return pd.read_csv(url)\n","\n","# List to hold the pandas DataFrames\n","df_dict = {}\n","\n","# Loop through each URL in the list of dictionaries\n","for csv_info in csv_urls:\n","    url = csv_info[\"csv_url\"]\n","    file_n = csv_info[\"file_name\"].replace(\".csv\", \"\")\n","    # Read the CSV into a pandas DataFrame\n","    pandas_df = read_dataframe(url)\n","    # Store the DataFrame in a dictionary with file_name as the key\n","    df_dict[file_n] = pandas_df"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"13956826-d9b6-4d6d-a0e0-6af303be61a8","normalized_state":"finished","queued_time":"2025-03-23T08:57:47.14702Z","session_start_time":null,"execution_start_time":"2025-03-23T08:57:47.1489611Z","execution_finish_time":"2025-03-23T08:57:51.5762643Z","parent_msg_id":"4036ca6f-fb49-4657-b301-daae7d75ba36"}},"metadata":{}}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"97a7eefa-16c4-45cc-8f82-63fbd921c75a"},{"cell_type":"code","source":["#display(df_dict)\n","df_dict[\"SalesLT.Address\"].head()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"13956826-d9b6-4d6d-a0e0-6af303be61a8","normalized_state":"finished","queued_time":"2025-03-23T09:00:40.0775753Z","session_start_time":null,"execution_start_time":"2025-03-23T09:00:40.0794176Z","execution_finish_time":"2025-03-23T09:00:40.5350283Z","parent_msg_id":"c30b87e1-d83c-443a-9990-fbc637b1a58e"}},"metadata":{}},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"   AddressID         AddressLine1  AddressLine2      City StateProvince  \\\n0          9    8713 Yosemite Ct.           NaN   Bothell    Washington   \n1         11  1318 Lasalle Street           NaN   Bothell    Washington   \n2         25     9178 Jumping St.           NaN    Dallas         Texas   \n3         28     9228 Via Del Sol           NaN   Phoenix       Arizona   \n4         32    26910 Indela Road           NaN  Montreal        Quebec   \n\n   CountryRegion PostalCode                               rowguid  \\\n0  United States      98011  268AF621-76D7-4C78-9441-144FD139821A   \n1  United States      98011  981B3303-ACA2-49C7-9A96-FB670785B269   \n2  United States      75201  C8DF3BD9-48F0-4654-A8DD-14A67A84D3C6   \n3  United States      85004  12AE5EE1-FC3E-468B-9B92-3B970B169774   \n4         Canada    H1Y 2H5  84A95F62-3AE8-4E7E-BBD5-5A6F00CD982D   \n\n          ModifiedDate  \n0  2006-07-01 00:00:00  \n1  2007-04-01 00:00:00  \n2  2006-09-01 00:00:00  \n3  2005-09-01 00:00:00  \n4  2006-08-01 00:00:00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AddressID</th>\n      <th>AddressLine1</th>\n      <th>AddressLine2</th>\n      <th>City</th>\n      <th>StateProvince</th>\n      <th>CountryRegion</th>\n      <th>PostalCode</th>\n      <th>rowguid</th>\n      <th>ModifiedDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9</td>\n      <td>8713 Yosemite Ct.</td>\n      <td>NaN</td>\n      <td>Bothell</td>\n      <td>Washington</td>\n      <td>United States</td>\n      <td>98011</td>\n      <td>268AF621-76D7-4C78-9441-144FD139821A</td>\n      <td>2006-07-01 00:00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11</td>\n      <td>1318 Lasalle Street</td>\n      <td>NaN</td>\n      <td>Bothell</td>\n      <td>Washington</td>\n      <td>United States</td>\n      <td>98011</td>\n      <td>981B3303-ACA2-49C7-9A96-FB670785B269</td>\n      <td>2007-04-01 00:00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25</td>\n      <td>9178 Jumping St.</td>\n      <td>NaN</td>\n      <td>Dallas</td>\n      <td>Texas</td>\n      <td>United States</td>\n      <td>75201</td>\n      <td>C8DF3BD9-48F0-4654-A8DD-14A67A84D3C6</td>\n      <td>2006-09-01 00:00:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28</td>\n      <td>9228 Via Del Sol</td>\n      <td>NaN</td>\n      <td>Phoenix</td>\n      <td>Arizona</td>\n      <td>United States</td>\n      <td>85004</td>\n      <td>12AE5EE1-FC3E-468B-9B92-3B970B169774</td>\n      <td>2005-09-01 00:00:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>26910 Indela Road</td>\n      <td>NaN</td>\n      <td>Montreal</td>\n      <td>Quebec</td>\n      <td>Canada</td>\n      <td>H1Y 2H5</td>\n      <td>84A95F62-3AE8-4E7E-BBD5-5A6F00CD982D</td>\n      <td>2006-08-01 00:00:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"98f4ac8c-eb80-4614-9286-45bf34b72adf"},{"cell_type":"code","source":["import os\n","\n","table_names = df_dict.keys()\n","\n","for t in table_names:\n","    # DataFrame\n","    df = df_dict[t]\n","\n","    # Specify the output path for the Delta Parquet file\n","    output_path = f'/lakehouse/default/Files/{t}_W01_data_delta_bronze'\n","\n","    # Check if the file exists and delete it\n","    if os.path.exists(output_path):\n","       os.remove(output_path)\n","       print(f\"File '{output_path}' has been deleted.\")\n","    else:\n","       print(f\"File '{output_path}' does not exist.\")\n","\n","    # Write the DataFrame to a Delta Parquet file\n","    df.to_parquet(output_path, engine='pyarrow')\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"13956826-d9b6-4d6d-a0e0-6af303be61a8","normalized_state":"finished","queued_time":"2025-03-23T09:41:02.8818608Z","session_start_time":null,"execution_start_time":"2025-03-23T09:41:02.8837636Z","execution_finish_time":"2025-03-23T09:41:05.2731831Z","parent_msg_id":"fdf2da1b-8a5f-4910-a73a-c416a62afa72"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["File '/lakehouse/default/Files/SalesLT.Address_W01_data_delta_bronze' has been deleted.\nFile '/lakehouse/default/Files/SalesLT.Customer_W01_data_delta_bronze' has been deleted.\nFile '/lakehouse/default/Files/SalesLT.CustomerAddress_W01_data_delta_bronze' has been deleted.\nFile '/lakehouse/default/Files/SalesLT.Product_W01_data_delta_bronze' has been deleted.\nFile '/lakehouse/default/Files/SalesLT.ProductCategory_W01_data_delta_bronze' has been deleted.\nFile '/lakehouse/default/Files/SalesLT.ProductDescription_W01_data_delta_bronze' has been deleted.\nFile '/lakehouse/default/Files/SalesLT.ProductModel_W01_data_delta_bronze' has been deleted.\nFile '/lakehouse/default/Files/SalesLT.ProductModelProductDescription_W01_data_delta_bronze' has been deleted.\nFile '/lakehouse/default/Files/SalesLT.SalesOrderDetail_W01_data_delta_bronze' has been deleted.\nFile '/lakehouse/default/Files/SalesLT.SalesOrderHeader_W01_data_delta_bronze' has been deleted.\n"]}],"execution_count":33,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"91370b56-4664-4a48-ab20-8cbf2c22e521"}],"metadata":{"kernel_info":{"name":"jupyter","jupyter_kernel_name":"python3.11"},"kernelspec":{"name":"jupyter","language":"Jupyter","display_name":"Jupyter"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"jupyter_python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"61065c3d-8998-449d-bf03-e5d9db76f237","default_lakehouse_name":"W01_lakehouse","default_lakehouse_workspace_id":"51f10b7f-b647-4d0d-871c-008ff83f6aa2"}}},"nbformat":4,"nbformat_minor":5}
